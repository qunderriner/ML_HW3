{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quinnunderriner/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/quinnunderriner/anaconda3/lib/python3.7/site-packages/sklearn/grid_search.py:14: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, namedtuple, Sized\n",
      "/Users/quinnunderriner/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/quinnunderriner/anaconda3/lib/python3.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn import ensemble \n",
    "from sklearn import neighbors\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import ml_pipeline2\n",
    "from ml_pipeline2 import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support, precision_recall_curve\n",
    "from sklearn import ensemble \n",
    "from sklearn import neighbors\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    'decision_tree': tree.DecisionTreeClassifier(),\n",
    "    'logistic_regression': linear_model.LogisticRegression(), \n",
    "    'knn': neighbors.KNeighborsClassifier(),\n",
    "    'random_forest': ensemble.RandomForestClassifier(), \n",
    "    'support_vector_machine': svm.SVC(), \n",
    "    'boosting': ensemble.AdaBoostClassifier(),\n",
    "    'bagging': ensemble.BaggingClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "PARAMS = {\n",
    "    'decision_tree': {'max_depth': [5, 8, 20]},\n",
    "    'logistic_regression': {'C': [0.001,0.01,0.1,1,10]}, \n",
    "    'knn': {'n_neighbors': [5, 10, 25] },\n",
    "    'random_forest': {'n_estimators': [1, 10, 25, 50]}, \n",
    "    'support_vector_machine': {'c_values': [10**-2, 10**-1, 1 , 10, 10**2]}, \n",
    "    'boosting': {'n_estimators': [100, 50, 30]},\n",
    "    'bagging': {'n_estimators': [2, 10, 20]} \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data \n",
    "filename = \"projects_2012_2013.csv\"\n",
    "data = ml_pipeline2.load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out which columns have missing values\n",
    "#because students_reached is the only noncategorial data missing, only imputing median values\n",
    "#for this column and deleting rows with missing data from the others. \n",
    "data.columns[data.isna().any()].tolist()\n",
    "ml_pipeline2.impute_median(data, median_cols=[\"students_reached\"])#needs to be run before discretized \n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop values that wont be needed for prediction. Dropping location values here even though they likley\n",
    "#would help prediction because policy wise, we can't reconmond that schools move\n",
    "data = data.drop(['projectid', 'teacher_acctid', 'schoolid', 'school_ncesid',\n",
    "       'school_latitude', 'school_longitude', 'school_city', 'school_state',\n",
    "       'school_metro', 'school_county', \"school_district\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12117bcc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Create predictor variables. assign a value of 1 if a project was funded within 60 days, a \n",
    "#value of zero if not\n",
    "data['date_posted'] = pd.to_datetime(data['date_posted'], format='%m/%d/%y')\n",
    "data['datefullyfunded'] = pd.to_datetime(data['datefullyfunded'], format='%m/%d/%y')\n",
    "start_date = '2011-01-01'\n",
    "end = '2013-12-31'\n",
    "data[\"days_2_fund\"] = data['datefullyfunded'] - data['date_posted']\n",
    "data[\"days_2_fund\"] = data[\"days_2_fund\"].dt.days\n",
    "data['predvar'] = np.where(data['days_2_fund']<= 60, 1, 0)\n",
    "data['predvar'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Three columns (eligible_double_your_impact_match', 'school_charter', 'school_magnet) have true/false values, currently replacing\n",
    "#them with 1 for true\n",
    "data = data.replace({\"t\": 1, \"f\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11594b208>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#see relationship between poverty and how many students are affected\n",
    "sns.catplot(x=\"students_reached\", y=\"poverty_level\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12b4f5320>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Technology is the most common ask for funding \n",
    "data['resource_type'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dummy variables for categorical variables\n",
    "\n",
    "dummiez = [\"teacher_prefix\",\"primary_focus_area\",\"secondary_focus_area\",\"primary_focus_subject\",\"secondary_focus_subject\",\"resource_type\",\"poverty_level\",\"grade_level\"]\n",
    "\n",
    "for i in dummiez:\n",
    "    data = ml_pipeline2.dummy(data, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discrtize continous variables\n",
    "data = ml_pipeline2.discretize(data, \"students_reached\")\n",
    "data = ml_pipeline2.discretize(data, \"total_price_including_optional_support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    70502.000000\n",
      "mean         0.049374\n",
      "std          0.216650\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: school_charter, dtype: float64\n",
      "count    70502.00000\n",
      "mean         0.09821\n",
      "std          0.29760\n",
      "min          0.00000\n",
      "25%          0.00000\n",
      "50%          0.00000\n",
      "75%          0.00000\n",
      "max          1.00000\n",
      "Name: school_magnet, dtype: float64\n",
      "count     70502\n",
      "unique        4\n",
      "top           1\n",
      "freq      17627\n",
      "Name: total_price_including_optional_support, dtype: int64\n",
      "count     70502\n",
      "unique        4\n",
      "top           1\n",
      "freq      18762\n",
      "Name: students_reached, dtype: int64\n",
      "count    70502.000000\n",
      "mean         0.312431\n",
      "std          0.463488\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: eligible_double_your_impact_match, dtype: float64\n",
      "count                   70502\n",
      "unique                    730\n",
      "top       2013-09-03 00:00:00\n",
      "freq                      422\n",
      "first     2012-01-01 00:00:00\n",
      "last      2013-12-31 00:00:00\n",
      "Name: date_posted, dtype: object\n",
      "count                   70502\n",
      "unique                    843\n",
      "top       2013-10-24 00:00:00\n",
      "freq                      192\n",
      "first     2012-01-07 00:00:00\n",
      "last      2014-04-29 00:00:00\n",
      "Name: datefullyfunded, dtype: object\n",
      "count    70502.000000\n",
      "mean        48.272319\n",
      "std         31.984528\n",
      "min          5.000000\n",
      "25%         23.000000\n",
      "50%         41.000000\n",
      "75%         72.000000\n",
      "max        120.000000\n",
      "Name: days_2_fund, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.712689\n",
      "std          0.452511\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: predvar, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.000028\n",
      "std          0.005326\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: teacher_prefix_Dr., dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.132166\n",
      "std          0.338674\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: teacher_prefix_Mr., dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.483759\n",
      "std          0.499740\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: teacher_prefix_Mrs., dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.384046\n",
      "std          0.486372\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: teacher_prefix_Ms., dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.063984\n",
      "std          0.244726\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_area_Applied Learning, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.031247\n",
      "std          0.173987\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_area_Health & Sports, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.047474\n",
      "std          0.212652\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_area_History & Civics, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.455788\n",
      "std          0.498045\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_area_Literacy & Language, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.251057\n",
      "std          0.433624\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_area_Math & Science, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.085005\n",
      "std          0.278891\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_area_Music & The Arts, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.065445\n",
      "std          0.247311\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_area_Special Needs, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.134209\n",
      "std          0.340879\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_area_Applied Learning, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.035261\n",
      "std          0.184441\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_area_Health & Sports, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.079671\n",
      "std          0.270786\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_area_History & Civics, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.358784\n",
      "std          0.479647\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_area_Literacy & Language, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.260503\n",
      "std          0.438912\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_area_Math & Science, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.069232\n",
      "std          0.253850\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_area_Music & The Arts, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.062339\n",
      "std          0.241771\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_area_Special Needs, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.045006\n",
      "std          0.207318\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Applied Sciences, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.019333\n",
      "std          0.137693\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Character Education, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.004255\n",
      "std          0.065093\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Civics & Government, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.009333\n",
      "std          0.096157\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_College & Career Prep, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.002142\n",
      "std          0.046230\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Community Service, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.016695\n",
      "std          0.128125\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_ESL, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.021716\n",
      "std          0.145755\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Early Development, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.005163\n",
      "std          0.071669\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Economics, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.044736\n",
      "std          0.206726\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Environmental Science, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.003787\n",
      "std          0.061423\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Extracurricular, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.004681\n",
      "std          0.068256\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Foreign Languages, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.011617\n",
      "std          0.107154\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Gym & Fitness, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.032680\n",
      "std          0.177799\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Health & Life Science, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.013021\n",
      "std          0.113365\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Health & Wellness, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.023063\n",
      "std          0.150105\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_History & Geography, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.295921\n",
      "std          0.456459\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Literacy, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.138493\n",
      "std          0.345419\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Literature & Writing, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.128635\n",
      "std          0.334797\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Mathematics, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.027545\n",
      "std          0.163667\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Music, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.001830\n",
      "std          0.042737\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Nutrition, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.006553\n",
      "std          0.080686\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Other, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.001121\n",
      "std          0.033456\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Parent Involvement, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.016070\n",
      "std          0.125747\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Performing Arts, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.014992\n",
      "std          0.121523\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Social Sciences, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.065445\n",
      "std          0.247311\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Special Needs, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.004780\n",
      "std          0.068973\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Sports, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.041389\n",
      "std          0.199189\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: primary_focus_subject_Visual Arts, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.039928\n",
      "std          0.195791\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Applied Sciences, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.026978\n",
      "std          0.162020\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Character Education, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.008808\n",
      "std          0.093439\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Civics & Government, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    70502.000000\n",
      "mean         0.021092\n",
      "std          0.143691\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_College & Career Prep, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.006028\n",
      "std          0.077408\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Community Service, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.057927\n",
      "std          0.233608\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_ESL, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.042595\n",
      "std          0.201943\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Early Development, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.005262\n",
      "std          0.072351\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Economics, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.035375\n",
      "std          0.184727\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Environmental Science, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.009489\n",
      "std          0.096949\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Extracurricular, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.004638\n",
      "std          0.067946\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Foreign Languages, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.008879\n",
      "std          0.093811\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Gym & Fitness, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.036552\n",
      "std          0.187661\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Health & Life Science, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.018553\n",
      "std          0.134940\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Health & Wellness, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.034226\n",
      "std          0.181810\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_History & Geography, dtype: float64\n",
      "count    70502.00000\n",
      "mean         0.14967\n",
      "std          0.35675\n",
      "min          0.00000\n",
      "25%          0.00000\n",
      "50%          0.00000\n",
      "75%          0.00000\n",
      "max          1.00000\n",
      "Name: secondary_focus_subject_Literacy, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.146549\n",
      "std          0.353658\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Literature & Writing, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.148648\n",
      "std          0.355744\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Mathematics, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.013702\n",
      "std          0.116251\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Music, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.003050\n",
      "std          0.055139\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Nutrition, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.022099\n",
      "std          0.147006\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Other, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.005929\n",
      "std          0.076771\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Parent Involvement, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.028794\n",
      "std          0.167227\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Performing Arts, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.031375\n",
      "std          0.174330\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Social Sciences, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.062339\n",
      "std          0.241771\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Special Needs, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.004780\n",
      "std          0.068973\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Sports, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.026737\n",
      "std          0.161314\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: secondary_focus_subject_Visual Arts, dtype: float64\n",
      "count    70502.00000\n",
      "mean         0.17903\n",
      "std          0.38338\n",
      "min          0.00000\n",
      "25%          0.00000\n",
      "50%          0.00000\n",
      "75%          0.00000\n",
      "max          1.00000\n",
      "Name: resource_type_Books, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.105004\n",
      "std          0.306561\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: resource_type_Other, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.301339\n",
      "std          0.458843\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: resource_type_Supplies, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.406868\n",
      "std          0.491253\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: resource_type_Technology, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.006369\n",
      "std          0.079550\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: resource_type_Trips, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.001390\n",
      "std          0.037257\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: resource_type_Visitors, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.255808\n",
      "std          0.436318\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: poverty_level_high poverty, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.561587\n",
      "std          0.496196\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: poverty_level_highest poverty, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.027403\n",
      "std          0.163257\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: poverty_level_low poverty, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.155201\n",
      "std          0.362099\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: poverty_level_moderate poverty, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.334090\n",
      "std          0.471675\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: grade_level_Grades 3-5, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.160818\n",
      "std          0.367366\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: grade_level_Grades 6-8, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.107018\n",
      "std          0.309139\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: grade_level_Grades 9-12, dtype: float64\n",
      "count    70502.000000\n",
      "mean         0.398074\n",
      "std          0.489504\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: grade_level_Grades PreK-2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### get descriptive statististics for each column \n",
    "ml_pipeline2.describe_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7126890017304474"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent of projects that are fully funded in 60 days\n",
    "data.predvar.sum() / data.predvar.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create predictor variables. assign a value of 1 if a project was funded within 60 days, a \n",
    "#value of zero if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"predvar\"\n",
    "features = [x for x in data.columns if x not in [ 'projectid', 'date_posted', 'datefullyfunded','predvar', 'days_2_fund']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with random forest (from https://towardsdatascience.com/feature-selection-using-random-forest-26d7b747597f)\n",
    "\n",
    "X,y = get_xy(data, response, features)\n",
    "\n",
    "sel = sklearn.feature_selection.SelectFromModel(sklearn.ensemble.RandomForestClassifier(n_estimators = 100))\n",
    "sel.fit(X, y)\n",
    "\n",
    "chosen_features = data[features].columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave out slow models for now (and for analysis)\n",
    "df = run_the_models(data, ['boosting',\n",
    "                           'bagging', \n",
    "                           'random_forest', \n",
    "                           'decision_tree', \n",
    "                           'logistic_regression'], response, chosen_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision_at_0.01</th>\n",
       "      <th>precision_at_0.02</th>\n",
       "      <th>...</th>\n",
       "      <th>precision_at_0.2</th>\n",
       "      <th>precision_at_0.3</th>\n",
       "      <th>precision_at_0.5</th>\n",
       "      <th>recall_at_0.01</th>\n",
       "      <th>recall_at_0.02</th>\n",
       "      <th>recall_at_0.05</th>\n",
       "      <th>recall_at_0.1</th>\n",
       "      <th>recall_at_0.2</th>\n",
       "      <th>recall_at_0.3</th>\n",
       "      <th>recall_at_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boosting</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>0.839679</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.754293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boosting</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.527074</td>\n",
       "      <td>0.839424</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.754661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boosting</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.525520</td>\n",
       "      <td>0.840971</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.753960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'n_estimators': 2}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.549519</td>\n",
       "      <td>0.694133</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752682</td>\n",
       "      <td>0.757119</td>\n",
       "      <td>0.774884</td>\n",
       "      <td>0.907138</td>\n",
       "      <td>0.907138</td>\n",
       "      <td>0.907138</td>\n",
       "      <td>0.903317</td>\n",
       "      <td>0.885148</td>\n",
       "      <td>0.862581</td>\n",
       "      <td>0.628623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.548827</td>\n",
       "      <td>0.762587</td>\n",
       "      <td>0.744687</td>\n",
       "      <td>0.744765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750706</td>\n",
       "      <td>0.754649</td>\n",
       "      <td>0.769163</td>\n",
       "      <td>0.987743</td>\n",
       "      <td>0.987311</td>\n",
       "      <td>0.984138</td>\n",
       "      <td>0.967267</td>\n",
       "      <td>0.939005</td>\n",
       "      <td>0.895242</td>\n",
       "      <td>0.756020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.549282</td>\n",
       "      <td>0.770868</td>\n",
       "      <td>0.743981</td>\n",
       "      <td>0.743978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748779</td>\n",
       "      <td>0.752511</td>\n",
       "      <td>0.768806</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>0.993079</td>\n",
       "      <td>0.987383</td>\n",
       "      <td>0.978515</td>\n",
       "      <td>0.950685</td>\n",
       "      <td>0.913050</td>\n",
       "      <td>0.772963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.543602</td>\n",
       "      <td>0.729133</td>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.756424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758428</td>\n",
       "      <td>0.759525</td>\n",
       "      <td>0.768346</td>\n",
       "      <td>0.802235</td>\n",
       "      <td>0.802235</td>\n",
       "      <td>0.802235</td>\n",
       "      <td>0.802235</td>\n",
       "      <td>0.791565</td>\n",
       "      <td>0.779019</td>\n",
       "      <td>0.693727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.550857</td>\n",
       "      <td>0.773495</td>\n",
       "      <td>0.745102</td>\n",
       "      <td>0.745248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749929</td>\n",
       "      <td>0.753668</td>\n",
       "      <td>0.769423</td>\n",
       "      <td>0.989906</td>\n",
       "      <td>0.989402</td>\n",
       "      <td>0.987311</td>\n",
       "      <td>0.973540</td>\n",
       "      <td>0.950036</td>\n",
       "      <td>0.911031</td>\n",
       "      <td>0.777578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 25}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.549819</td>\n",
       "      <td>0.781318</td>\n",
       "      <td>0.743754</td>\n",
       "      <td>0.743964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749326</td>\n",
       "      <td>0.752571</td>\n",
       "      <td>0.768277</td>\n",
       "      <td>0.995890</td>\n",
       "      <td>0.995314</td>\n",
       "      <td>0.991565</td>\n",
       "      <td>0.984571</td>\n",
       "      <td>0.961644</td>\n",
       "      <td>0.923432</td>\n",
       "      <td>0.794809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.549899</td>\n",
       "      <td>0.784520</td>\n",
       "      <td>0.743577</td>\n",
       "      <td>0.744007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>0.753190</td>\n",
       "      <td>0.768099</td>\n",
       "      <td>0.997477</td>\n",
       "      <td>0.995746</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.984283</td>\n",
       "      <td>0.962870</td>\n",
       "      <td>0.927614</td>\n",
       "      <td>0.801658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.545608</td>\n",
       "      <td>0.821601</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.763671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.536960</td>\n",
       "      <td>0.824348</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>0.746875</td>\n",
       "      <td>0.759555</td>\n",
       "      <td>0.996972</td>\n",
       "      <td>0.996972</td>\n",
       "      <td>0.996972</td>\n",
       "      <td>0.996972</td>\n",
       "      <td>0.996972</td>\n",
       "      <td>0.977938</td>\n",
       "      <td>0.901226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 20}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.550246</td>\n",
       "      <td>0.727127</td>\n",
       "      <td>0.755021</td>\n",
       "      <td>0.755021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756081</td>\n",
       "      <td>0.757857</td>\n",
       "      <td>0.772569</td>\n",
       "      <td>0.818601</td>\n",
       "      <td>0.818601</td>\n",
       "      <td>0.818601</td>\n",
       "      <td>0.818601</td>\n",
       "      <td>0.813482</td>\n",
       "      <td>0.806705</td>\n",
       "      <td>0.686734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.502574</td>\n",
       "      <td>0.851951</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.744567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.521331</td>\n",
       "      <td>0.839731</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.752240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.533151</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.757367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.535952</td>\n",
       "      <td>0.834188</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.758680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>0.536442</td>\n",
       "      <td>0.833545</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.758923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>boosting</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.813145</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.689368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>boosting</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.509535</td>\n",
       "      <td>0.812957</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.689442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>boosting</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.509272</td>\n",
       "      <td>0.813391</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'n_estimators': 2}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.536653</td>\n",
       "      <td>0.711620</td>\n",
       "      <td>0.689772</td>\n",
       "      <td>0.689772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692041</td>\n",
       "      <td>0.695361</td>\n",
       "      <td>0.708108</td>\n",
       "      <td>0.941253</td>\n",
       "      <td>0.941253</td>\n",
       "      <td>0.941135</td>\n",
       "      <td>0.939236</td>\n",
       "      <td>0.922502</td>\n",
       "      <td>0.900190</td>\n",
       "      <td>0.715167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.534180</td>\n",
       "      <td>0.757657</td>\n",
       "      <td>0.685677</td>\n",
       "      <td>0.685677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688843</td>\n",
       "      <td>0.691668</td>\n",
       "      <td>0.703715</td>\n",
       "      <td>0.990268</td>\n",
       "      <td>0.990268</td>\n",
       "      <td>0.988369</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>0.958462</td>\n",
       "      <td>0.928080</td>\n",
       "      <td>0.820555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.532021</td>\n",
       "      <td>0.759016</td>\n",
       "      <td>0.686106</td>\n",
       "      <td>0.686034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689107</td>\n",
       "      <td>0.691169</td>\n",
       "      <td>0.702413</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.996321</td>\n",
       "      <td>0.990980</td>\n",
       "      <td>0.984690</td>\n",
       "      <td>0.967007</td>\n",
       "      <td>0.936269</td>\n",
       "      <td>0.825540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.729945</td>\n",
       "      <td>0.695427</td>\n",
       "      <td>0.695427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697057</td>\n",
       "      <td>0.698352</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>0.875267</td>\n",
       "      <td>0.875267</td>\n",
       "      <td>0.875267</td>\n",
       "      <td>0.875030</td>\n",
       "      <td>0.865654</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.751602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.527735</td>\n",
       "      <td>0.759635</td>\n",
       "      <td>0.685911</td>\n",
       "      <td>0.685890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688292</td>\n",
       "      <td>0.689942</td>\n",
       "      <td>0.699629</td>\n",
       "      <td>0.992642</td>\n",
       "      <td>0.992286</td>\n",
       "      <td>0.989675</td>\n",
       "      <td>0.979824</td>\n",
       "      <td>0.960717</td>\n",
       "      <td>0.934607</td>\n",
       "      <td>0.828744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 25}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.532476</td>\n",
       "      <td>0.764470</td>\n",
       "      <td>0.685391</td>\n",
       "      <td>0.685451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687779</td>\n",
       "      <td>0.690189</td>\n",
       "      <td>0.702297</td>\n",
       "      <td>0.997745</td>\n",
       "      <td>0.997508</td>\n",
       "      <td>0.993829</td>\n",
       "      <td>0.987183</td>\n",
       "      <td>0.967838</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.838239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.533134</td>\n",
       "      <td>0.769239</td>\n",
       "      <td>0.685068</td>\n",
       "      <td>0.685554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688166</td>\n",
       "      <td>0.690098</td>\n",
       "      <td>0.702472</td>\n",
       "      <td>0.998576</td>\n",
       "      <td>0.997982</td>\n",
       "      <td>0.994778</td>\n",
       "      <td>0.987895</td>\n",
       "      <td>0.973772</td>\n",
       "      <td>0.943746</td>\n",
       "      <td>0.849869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.813242</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.517550</td>\n",
       "      <td>0.806493</td>\n",
       "      <td>0.685333</td>\n",
       "      <td>0.685333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685304</td>\n",
       "      <td>0.685637</td>\n",
       "      <td>0.693207</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.997864</td>\n",
       "      <td>0.996558</td>\n",
       "      <td>0.964040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 20}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.541219</td>\n",
       "      <td>0.734897</td>\n",
       "      <td>0.691904</td>\n",
       "      <td>0.691904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692051</td>\n",
       "      <td>0.693814</td>\n",
       "      <td>0.709410</td>\n",
       "      <td>0.891526</td>\n",
       "      <td>0.891526</td>\n",
       "      <td>0.891526</td>\n",
       "      <td>0.891526</td>\n",
       "      <td>0.887610</td>\n",
       "      <td>0.878590</td>\n",
       "      <td>0.762283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.500423</td>\n",
       "      <td>0.812624</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.510247</td>\n",
       "      <td>0.813650</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.689749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.515147</td>\n",
       "      <td>0.812295</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.691974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.515941</td>\n",
       "      <td>0.811419</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.692353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>0.516150</td>\n",
       "      <td>0.811363</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>0.692450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>boosting</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.526215</td>\n",
       "      <td>0.831871</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.728318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>boosting</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.526567</td>\n",
       "      <td>0.831657</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.728480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>boosting</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.524310</td>\n",
       "      <td>0.831492</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.727492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'n_estimators': 2}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.545526</td>\n",
       "      <td>0.728762</td>\n",
       "      <td>0.722878</td>\n",
       "      <td>0.722878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724955</td>\n",
       "      <td>0.727355</td>\n",
       "      <td>0.744010</td>\n",
       "      <td>0.949111</td>\n",
       "      <td>0.949111</td>\n",
       "      <td>0.949111</td>\n",
       "      <td>0.945763</td>\n",
       "      <td>0.928965</td>\n",
       "      <td>0.898407</td>\n",
       "      <td>0.714126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.544240</td>\n",
       "      <td>0.767701</td>\n",
       "      <td>0.718708</td>\n",
       "      <td>0.718747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722069</td>\n",
       "      <td>0.724983</td>\n",
       "      <td>0.740455</td>\n",
       "      <td>0.992996</td>\n",
       "      <td>0.992872</td>\n",
       "      <td>0.990268</td>\n",
       "      <td>0.981157</td>\n",
       "      <td>0.959462</td>\n",
       "      <td>0.927788</td>\n",
       "      <td>0.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bagging</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.546422</td>\n",
       "      <td>0.773350</td>\n",
       "      <td>0.718165</td>\n",
       "      <td>0.718295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721467</td>\n",
       "      <td>0.724755</td>\n",
       "      <td>0.741261</td>\n",
       "      <td>0.996653</td>\n",
       "      <td>0.996343</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.987107</td>\n",
       "      <td>0.967024</td>\n",
       "      <td>0.939131</td>\n",
       "      <td>0.808343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.545348</td>\n",
       "      <td>0.738801</td>\n",
       "      <td>0.723692</td>\n",
       "      <td>0.723692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724750</td>\n",
       "      <td>0.727076</td>\n",
       "      <td>0.743133</td>\n",
       "      <td>0.880245</td>\n",
       "      <td>0.880245</td>\n",
       "      <td>0.880245</td>\n",
       "      <td>0.879316</td>\n",
       "      <td>0.870886</td>\n",
       "      <td>0.853716</td>\n",
       "      <td>0.734519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.719059</td>\n",
       "      <td>0.718983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722096</td>\n",
       "      <td>0.725450</td>\n",
       "      <td>0.739486</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.992128</td>\n",
       "      <td>0.991322</td>\n",
       "      <td>0.982520</td>\n",
       "      <td>0.964421</td>\n",
       "      <td>0.932747</td>\n",
       "      <td>0.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 25}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.542261</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.718072</td>\n",
       "      <td>0.718292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722145</td>\n",
       "      <td>0.724540</td>\n",
       "      <td>0.738692</td>\n",
       "      <td>0.997459</td>\n",
       "      <td>0.996963</td>\n",
       "      <td>0.994173</td>\n",
       "      <td>0.988843</td>\n",
       "      <td>0.971425</td>\n",
       "      <td>0.942850</td>\n",
       "      <td>0.820926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.544352</td>\n",
       "      <td>0.780125</td>\n",
       "      <td>0.717574</td>\n",
       "      <td>0.718353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721144</td>\n",
       "      <td>0.724530</td>\n",
       "      <td>0.739652</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.997893</td>\n",
       "      <td>0.995537</td>\n",
       "      <td>0.989277</td>\n",
       "      <td>0.973966</td>\n",
       "      <td>0.943780</td>\n",
       "      <td>0.825203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.534680</td>\n",
       "      <td>0.824995</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.525324</td>\n",
       "      <td>0.828183</td>\n",
       "      <td>0.717057</td>\n",
       "      <td>0.717057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717141</td>\n",
       "      <td>0.717128</td>\n",
       "      <td>0.728042</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>0.998698</td>\n",
       "      <td>0.998698</td>\n",
       "      <td>0.998636</td>\n",
       "      <td>0.960268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 20}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.544409</td>\n",
       "      <td>0.744610</td>\n",
       "      <td>0.722858</td>\n",
       "      <td>0.722858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723236</td>\n",
       "      <td>0.725323</td>\n",
       "      <td>0.742134</td>\n",
       "      <td>0.904234</td>\n",
       "      <td>0.904234</td>\n",
       "      <td>0.904234</td>\n",
       "      <td>0.904234</td>\n",
       "      <td>0.899461</td>\n",
       "      <td>0.888613</td>\n",
       "      <td>0.747102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.506451</td>\n",
       "      <td>0.833668</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.719834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.525980</td>\n",
       "      <td>0.830955</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.728244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.732183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.536933</td>\n",
       "      <td>0.828633</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.733263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.537092</td>\n",
       "      <td>0.828564</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.717182</td>\n",
       "      <td>0.733340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model             parameters train_start  train_end  \\\n",
       "0              boosting  {'n_estimators': 100}  2012-01-01 2012-07-31   \n",
       "1              boosting   {'n_estimators': 50}  2012-01-01 2012-07-31   \n",
       "2              boosting   {'n_estimators': 30}  2012-01-01 2012-07-31   \n",
       "3               bagging    {'n_estimators': 2}  2012-01-01 2012-07-31   \n",
       "4               bagging   {'n_estimators': 10}  2012-01-01 2012-07-31   \n",
       "5               bagging   {'n_estimators': 20}  2012-01-01 2012-07-31   \n",
       "6         random_forest    {'n_estimators': 1}  2012-01-01 2012-07-31   \n",
       "7         random_forest   {'n_estimators': 10}  2012-01-01 2012-07-31   \n",
       "8         random_forest   {'n_estimators': 25}  2012-01-01 2012-07-31   \n",
       "9         random_forest   {'n_estimators': 50}  2012-01-01 2012-07-31   \n",
       "10        decision_tree       {'max_depth': 5}  2012-01-01 2012-07-31   \n",
       "11        decision_tree       {'max_depth': 8}  2012-01-01 2012-07-31   \n",
       "12        decision_tree      {'max_depth': 20}  2012-01-01 2012-07-31   \n",
       "13  logistic_regression           {'C': 0.001}  2012-01-01 2012-07-31   \n",
       "14  logistic_regression            {'C': 0.01}  2012-01-01 2012-07-31   \n",
       "15  logistic_regression             {'C': 0.1}  2012-01-01 2012-07-31   \n",
       "16  logistic_regression               {'C': 1}  2012-01-01 2012-07-31   \n",
       "17  logistic_regression              {'C': 10}  2012-01-01 2012-07-31   \n",
       "18             boosting  {'n_estimators': 100}  2012-01-01 2013-01-31   \n",
       "19             boosting   {'n_estimators': 50}  2012-01-01 2013-01-31   \n",
       "20             boosting   {'n_estimators': 30}  2012-01-01 2013-01-31   \n",
       "21              bagging    {'n_estimators': 2}  2012-01-01 2013-01-31   \n",
       "22              bagging   {'n_estimators': 10}  2012-01-01 2013-01-31   \n",
       "23              bagging   {'n_estimators': 20}  2012-01-01 2013-01-31   \n",
       "24        random_forest    {'n_estimators': 1}  2012-01-01 2013-01-31   \n",
       "25        random_forest   {'n_estimators': 10}  2012-01-01 2013-01-31   \n",
       "26        random_forest   {'n_estimators': 25}  2012-01-01 2013-01-31   \n",
       "27        random_forest   {'n_estimators': 50}  2012-01-01 2013-01-31   \n",
       "28        decision_tree       {'max_depth': 5}  2012-01-01 2013-01-31   \n",
       "29        decision_tree       {'max_depth': 8}  2012-01-01 2013-01-31   \n",
       "30        decision_tree      {'max_depth': 20}  2012-01-01 2013-01-31   \n",
       "31  logistic_regression           {'C': 0.001}  2012-01-01 2013-01-31   \n",
       "32  logistic_regression            {'C': 0.01}  2012-01-01 2013-01-31   \n",
       "33  logistic_regression             {'C': 0.1}  2012-01-01 2013-01-31   \n",
       "34  logistic_regression               {'C': 1}  2012-01-01 2013-01-31   \n",
       "35  logistic_regression              {'C': 10}  2012-01-01 2013-01-31   \n",
       "36             boosting  {'n_estimators': 100}  2012-01-01 2013-07-31   \n",
       "37             boosting   {'n_estimators': 50}  2012-01-01 2013-07-31   \n",
       "38             boosting   {'n_estimators': 30}  2012-01-01 2013-07-31   \n",
       "39              bagging    {'n_estimators': 2}  2012-01-01 2013-07-31   \n",
       "40              bagging   {'n_estimators': 10}  2012-01-01 2013-07-31   \n",
       "41              bagging   {'n_estimators': 20}  2012-01-01 2013-07-31   \n",
       "42        random_forest    {'n_estimators': 1}  2012-01-01 2013-07-31   \n",
       "43        random_forest   {'n_estimators': 10}  2012-01-01 2013-07-31   \n",
       "44        random_forest   {'n_estimators': 25}  2012-01-01 2013-07-31   \n",
       "45        random_forest   {'n_estimators': 50}  2012-01-01 2013-07-31   \n",
       "46        decision_tree       {'max_depth': 5}  2012-01-01 2013-07-31   \n",
       "47        decision_tree       {'max_depth': 8}  2012-01-01 2013-07-31   \n",
       "48        decision_tree      {'max_depth': 20}  2012-01-01 2013-07-31   \n",
       "49  logistic_regression           {'C': 0.001}  2012-01-01 2013-07-31   \n",
       "50  logistic_regression            {'C': 0.01}  2012-01-01 2013-07-31   \n",
       "51  logistic_regression             {'C': 0.1}  2012-01-01 2013-07-31   \n",
       "52  logistic_regression               {'C': 1}  2012-01-01 2013-07-31   \n",
       "53  logistic_regression              {'C': 10}  2012-01-01 2013-07-31   \n",
       "\n",
       "   test_start   test_end  f1_score       auc  precision_at_0.01  \\\n",
       "0  2012-07-31 2013-01-31  0.526223  0.839679           0.743580   \n",
       "1  2012-07-31 2013-01-31  0.527074  0.839424           0.743580   \n",
       "2  2012-07-31 2013-01-31  0.525520  0.840971           0.743580   \n",
       "3  2012-07-31 2013-01-31  0.549519  0.694133           0.750940   \n",
       "4  2012-07-31 2013-01-31  0.548827  0.762587           0.744687   \n",
       "5  2012-07-31 2013-01-31  0.549282  0.770868           0.743981   \n",
       "6  2012-07-31 2013-01-31  0.543602  0.729133           0.756424   \n",
       "7  2012-07-31 2013-01-31  0.550857  0.773495           0.745102   \n",
       "8  2012-07-31 2013-01-31  0.549819  0.781318           0.743754   \n",
       "9  2012-07-31 2013-01-31  0.549899  0.784520           0.743577   \n",
       "10 2012-07-31 2013-01-31  0.545608  0.821601           0.743580   \n",
       "11 2012-07-31 2013-01-31  0.536960  0.824348           0.743481   \n",
       "12 2012-07-31 2013-01-31  0.550246  0.727127           0.755021   \n",
       "13 2012-07-31 2013-01-31  0.502574  0.851951           0.743580   \n",
       "14 2012-07-31 2013-01-31  0.521331  0.839731           0.743580   \n",
       "15 2012-07-31 2013-01-31  0.533151  0.836443           0.743580   \n",
       "16 2012-07-31 2013-01-31  0.535952  0.834188           0.743580   \n",
       "17 2012-07-31 2013-01-31  0.536442  0.833545           0.743580   \n",
       "18 2013-01-31 2013-07-31  0.509374  0.813145           0.685264   \n",
       "19 2013-01-31 2013-07-31  0.509535  0.812957           0.685264   \n",
       "20 2013-01-31 2013-07-31  0.509272  0.813391           0.685264   \n",
       "21 2013-01-31 2013-07-31  0.536653  0.711620           0.689772   \n",
       "22 2013-01-31 2013-07-31  0.534180  0.757657           0.685677   \n",
       "23 2013-01-31 2013-07-31  0.532021  0.759016           0.686106   \n",
       "24 2013-01-31 2013-07-31  0.540788  0.729945           0.695427   \n",
       "25 2013-01-31 2013-07-31  0.527735  0.759635           0.685911   \n",
       "26 2013-01-31 2013-07-31  0.532476  0.764470           0.685391   \n",
       "27 2013-01-31 2013-07-31  0.533134  0.769239           0.685068   \n",
       "28 2013-01-31 2013-07-31  0.500000  0.813242           0.685264   \n",
       "29 2013-01-31 2013-07-31  0.517550  0.806493           0.685333   \n",
       "30 2013-01-31 2013-07-31  0.541219  0.734897           0.691904   \n",
       "31 2013-01-31 2013-07-31  0.500423  0.812624           0.685264   \n",
       "32 2013-01-31 2013-07-31  0.510247  0.813650           0.685264   \n",
       "33 2013-01-31 2013-07-31  0.515147  0.812295           0.685264   \n",
       "34 2013-01-31 2013-07-31  0.515941  0.811419           0.685264   \n",
       "35 2013-01-31 2013-07-31  0.516150  0.811363           0.685264   \n",
       "36 2013-07-31 2013-12-31  0.526215  0.831871           0.717182   \n",
       "37 2013-07-31 2013-12-31  0.526567  0.831657           0.717182   \n",
       "38 2013-07-31 2013-12-31  0.524310  0.831492           0.717182   \n",
       "39 2013-07-31 2013-12-31  0.545526  0.728762           0.722878   \n",
       "40 2013-07-31 2013-12-31  0.544240  0.767701           0.718708   \n",
       "41 2013-07-31 2013-12-31  0.546422  0.773350           0.718165   \n",
       "42 2013-07-31 2013-12-31  0.545348  0.738801           0.723692   \n",
       "43 2013-07-31 2013-12-31  0.543300  0.774049           0.719059   \n",
       "44 2013-07-31 2013-12-31  0.542261  0.777641           0.718072   \n",
       "45 2013-07-31 2013-12-31  0.544352  0.780125           0.717574   \n",
       "46 2013-07-31 2013-12-31  0.534680  0.824995           0.717182   \n",
       "47 2013-07-31 2013-12-31  0.525324  0.828183           0.717057   \n",
       "48 2013-07-31 2013-12-31  0.544409  0.744610           0.722858   \n",
       "49 2013-07-31 2013-12-31  0.506451  0.833668           0.717182   \n",
       "50 2013-07-31 2013-12-31  0.525980  0.830955           0.717182   \n",
       "51 2013-07-31 2013-12-31  0.534668  0.829671           0.717182   \n",
       "52 2013-07-31 2013-12-31  0.536933  0.828633           0.717182   \n",
       "53 2013-07-31 2013-12-31  0.537092  0.828564           0.717182   \n",
       "\n",
       "    precision_at_0.02  ...  precision_at_0.2  precision_at_0.3  \\\n",
       "0            0.743580  ...          0.743580          0.743580   \n",
       "1            0.743580  ...          0.743580          0.743580   \n",
       "2            0.743580  ...          0.743580          0.743580   \n",
       "3            0.750940  ...          0.752682          0.757119   \n",
       "4            0.744765  ...          0.750706          0.754649   \n",
       "5            0.743978  ...          0.748779          0.752511   \n",
       "6            0.756424  ...          0.758428          0.759525   \n",
       "7            0.745248  ...          0.749929          0.753668   \n",
       "8            0.743964  ...          0.749326          0.752571   \n",
       "9            0.744007  ...          0.748389          0.753190   \n",
       "10           0.743580  ...          0.743580          0.743580   \n",
       "11           0.743481  ...          0.743481          0.746875   \n",
       "12           0.755021  ...          0.756081          0.757857   \n",
       "13           0.743580  ...          0.743580          0.743580   \n",
       "14           0.743580  ...          0.743580          0.743580   \n",
       "15           0.743580  ...          0.743580          0.743580   \n",
       "16           0.743580  ...          0.743580          0.743580   \n",
       "17           0.743580  ...          0.743580          0.743580   \n",
       "18           0.685264  ...          0.685264          0.685264   \n",
       "19           0.685264  ...          0.685264          0.685264   \n",
       "20           0.685264  ...          0.685264          0.685264   \n",
       "21           0.689772  ...          0.692041          0.695361   \n",
       "22           0.685677  ...          0.688843          0.691668   \n",
       "23           0.686034  ...          0.689107          0.691169   \n",
       "24           0.695427  ...          0.697057          0.698352   \n",
       "25           0.685890  ...          0.688292          0.689942   \n",
       "26           0.685451  ...          0.687779          0.690189   \n",
       "27           0.685554  ...          0.688166          0.690098   \n",
       "28           0.685264  ...          0.685264          0.685264   \n",
       "29           0.685333  ...          0.685304          0.685637   \n",
       "30           0.691904  ...          0.692051          0.693814   \n",
       "31           0.685264  ...          0.685264          0.685264   \n",
       "32           0.685264  ...          0.685264          0.685264   \n",
       "33           0.685264  ...          0.685264          0.685264   \n",
       "34           0.685264  ...          0.685264          0.685264   \n",
       "35           0.685264  ...          0.685264          0.685264   \n",
       "36           0.717182  ...          0.717182          0.717182   \n",
       "37           0.717182  ...          0.717182          0.717182   \n",
       "38           0.717182  ...          0.717182          0.717182   \n",
       "39           0.722878  ...          0.724955          0.727355   \n",
       "40           0.718747  ...          0.722069          0.724983   \n",
       "41           0.718295  ...          0.721467          0.724755   \n",
       "42           0.723692  ...          0.724750          0.727076   \n",
       "43           0.718983  ...          0.722096          0.725450   \n",
       "44           0.718292  ...          0.722145          0.724540   \n",
       "45           0.718353  ...          0.721144          0.724530   \n",
       "46           0.717182  ...          0.717182          0.717182   \n",
       "47           0.717057  ...          0.717141          0.717128   \n",
       "48           0.722858  ...          0.723236          0.725323   \n",
       "49           0.717182  ...          0.717182          0.717182   \n",
       "50           0.717182  ...          0.717182          0.717182   \n",
       "51           0.717182  ...          0.717182          0.717182   \n",
       "52           0.717182  ...          0.717182          0.717182   \n",
       "53           0.717182  ...          0.717182          0.717182   \n",
       "\n",
       "    precision_at_0.5  recall_at_0.01  recall_at_0.02  recall_at_0.05  \\\n",
       "0           0.754293        1.000000        1.000000        1.000000   \n",
       "1           0.754661        1.000000        1.000000        1.000000   \n",
       "2           0.753960        1.000000        1.000000        1.000000   \n",
       "3           0.774884        0.907138        0.907138        0.907138   \n",
       "4           0.769163        0.987743        0.987311        0.984138   \n",
       "5           0.768806        0.993727        0.993079        0.987383   \n",
       "6           0.768346        0.802235        0.802235        0.802235   \n",
       "7           0.769423        0.989906        0.989402        0.987311   \n",
       "8           0.768277        0.995890        0.995314        0.991565   \n",
       "9           0.768099        0.997477        0.995746        0.992430   \n",
       "10          0.763671        1.000000        1.000000        1.000000   \n",
       "11          0.759555        0.996972        0.996972        0.996972   \n",
       "12          0.772569        0.818601        0.818601        0.818601   \n",
       "13          0.744567        1.000000        1.000000        1.000000   \n",
       "14          0.752240        1.000000        1.000000        1.000000   \n",
       "15          0.757367        1.000000        1.000000        1.000000   \n",
       "16          0.758680        1.000000        1.000000        1.000000   \n",
       "17          0.758923        1.000000        1.000000        1.000000   \n",
       "18          0.689368        1.000000        1.000000        1.000000   \n",
       "19          0.689442        1.000000        1.000000        1.000000   \n",
       "20          0.689320        1.000000        1.000000        1.000000   \n",
       "21          0.708108        0.941253        0.941253        0.941135   \n",
       "22          0.703715        0.990268        0.990268        0.988369   \n",
       "23          0.702413        0.996914        0.996321        0.990980   \n",
       "24          0.709500        0.875267        0.875267        0.875267   \n",
       "25          0.699629        0.992642        0.992286        0.989675   \n",
       "26          0.702297        0.997745        0.997508        0.993829   \n",
       "27          0.702472        0.998576        0.997982        0.994778   \n",
       "28          0.685264        1.000000        1.000000        1.000000   \n",
       "29          0.693207        0.999288        0.999288        0.999288   \n",
       "30          0.709410        0.891526        0.891526        0.891526   \n",
       "31          0.685446        1.000000        1.000000        1.000000   \n",
       "32          0.689749        1.000000        1.000000        1.000000   \n",
       "33          0.691974        1.000000        1.000000        1.000000   \n",
       "34          0.692353        1.000000        1.000000        1.000000   \n",
       "35          0.692450        1.000000        1.000000        1.000000   \n",
       "36          0.728318        1.000000        1.000000        1.000000   \n",
       "37          0.728480        1.000000        1.000000        1.000000   \n",
       "38          0.727492        1.000000        1.000000        1.000000   \n",
       "39          0.744010        0.949111        0.949111        0.949111   \n",
       "40          0.740455        0.992996        0.992872        0.990268   \n",
       "41          0.741261        0.996653        0.996343        0.992500   \n",
       "42          0.743133        0.880245        0.880245        0.880245   \n",
       "43          0.739486        0.992500        0.992128        0.991322   \n",
       "44          0.738692        0.997459        0.996963        0.994173   \n",
       "45          0.739652        0.998946        0.997893        0.995537   \n",
       "46          0.732394        1.000000        1.000000        1.000000   \n",
       "47          0.728042        0.999070        0.999070        0.999070   \n",
       "48          0.742134        0.904234        0.904234        0.904234   \n",
       "49          0.719834        1.000000        1.000000        1.000000   \n",
       "50          0.728244        1.000000        1.000000        1.000000   \n",
       "51          0.732183        1.000000        1.000000        1.000000   \n",
       "52          0.733263        1.000000        1.000000        1.000000   \n",
       "53          0.733340        1.000000        1.000000        1.000000   \n",
       "\n",
       "    recall_at_0.1  recall_at_0.2  recall_at_0.3  recall_at_0.5  \n",
       "0        1.000000       1.000000       1.000000       0.946864  \n",
       "1        1.000000       1.000000       1.000000       0.945638  \n",
       "2        1.000000       1.000000       1.000000       0.950685  \n",
       "3        0.903317       0.885148       0.862581       0.628623  \n",
       "4        0.967267       0.939005       0.895242       0.756020  \n",
       "5        0.978515       0.950685       0.913050       0.772963  \n",
       "6        0.802235       0.791565       0.779019       0.693727  \n",
       "7        0.973540       0.950036       0.911031       0.777578  \n",
       "8        0.984571       0.961644       0.923432       0.794809  \n",
       "9        0.984283       0.962870       0.927614       0.801658  \n",
       "10       1.000000       1.000000       1.000000       0.889041  \n",
       "11       0.996972       0.996972       0.977938       0.901226  \n",
       "12       0.818601       0.813482       0.806705       0.686734  \n",
       "13       1.000000       1.000000       1.000000       0.995530  \n",
       "14       1.000000       1.000000       1.000000       0.950252  \n",
       "15       1.000000       1.000000       1.000000       0.933958  \n",
       "16       1.000000       1.000000       1.000000       0.926388  \n",
       "17       1.000000       1.000000       1.000000       0.924441  \n",
       "18       1.000000       1.000000       1.000000       0.991099  \n",
       "19       1.000000       1.000000       1.000000       0.990387  \n",
       "20       1.000000       1.000000       1.000000       0.991930  \n",
       "21       0.939236       0.922502       0.900190       0.715167  \n",
       "22       0.978875       0.958462       0.928080       0.820555  \n",
       "23       0.984690       0.967007       0.936269       0.825540  \n",
       "24       0.875030       0.865654       0.850107       0.751602  \n",
       "25       0.979824       0.960717       0.934607       0.828744  \n",
       "26       0.987183       0.967838       0.942559       0.838239  \n",
       "27       0.987895       0.973772       0.943746       0.849869  \n",
       "28       1.000000       1.000000       1.000000       1.000000  \n",
       "29       0.999288       0.997864       0.996558       0.964040  \n",
       "30       0.891526       0.887610       0.878590       0.762283  \n",
       "31       1.000000       1.000000       1.000000       0.997745  \n",
       "32       1.000000       1.000000       1.000000       0.991811  \n",
       "33       1.000000       1.000000       1.000000       0.983266  \n",
       "34       1.000000       1.000000       1.000000       0.979943  \n",
       "35       1.000000       1.000000       1.000000       0.979587  \n",
       "36       1.000000       1.000000       1.000000       0.969751  \n",
       "37       1.000000       1.000000       1.000000       0.968884  \n",
       "38       1.000000       1.000000       1.000000       0.970185  \n",
       "39       0.945763       0.928965       0.898407       0.714126  \n",
       "40       0.981157       0.959462       0.927788       0.797000  \n",
       "41       0.987107       0.967024       0.939131       0.808343  \n",
       "42       0.879316       0.870886       0.853716       0.734519  \n",
       "43       0.982520       0.964421       0.932747       0.812000  \n",
       "44       0.988843       0.971425       0.942850       0.820926  \n",
       "45       0.989277       0.973966       0.943780       0.825203  \n",
       "46       1.000000       1.000000       1.000000       0.944400  \n",
       "47       0.998698       0.998698       0.998636       0.960268  \n",
       "48       0.904234       0.899461       0.888613       0.747102  \n",
       "49       1.000000       1.000000       1.000000       0.990268  \n",
       "50       1.000000       1.000000       1.000000       0.967396  \n",
       "51       1.000000       1.000000       1.000000       0.957107  \n",
       "52       1.000000       1.000000       1.000000       0.952520  \n",
       "53       1.000000       1.000000       1.000000       0.952210  \n",
       "\n",
       "[54 rows x 22 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision_at_0.5</th>\n",
       "      <th>recall_at_0.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <th>{'max_depth': 20}</th>\n",
       "      <td>0.545291</td>\n",
       "      <td>0.735545</td>\n",
       "      <td>0.741371</td>\n",
       "      <td>0.732040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <th>{'n_estimators': 2}</th>\n",
       "      <td>0.543900</td>\n",
       "      <td>0.711505</td>\n",
       "      <td>0.742334</td>\n",
       "      <td>0.685972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <th>{'n_estimators': 1}</th>\n",
       "      <td>0.543246</td>\n",
       "      <td>0.732626</td>\n",
       "      <td>0.740327</td>\n",
       "      <td>0.726616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <th>{'n_estimators': 20}</th>\n",
       "      <td>0.542575</td>\n",
       "      <td>0.767744</td>\n",
       "      <td>0.737493</td>\n",
       "      <td>0.802282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <th>{'n_estimators': 50}</th>\n",
       "      <td>0.542461</td>\n",
       "      <td>0.777961</td>\n",
       "      <td>0.736741</td>\n",
       "      <td>0.825577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <th>{'n_estimators': 10}</th>\n",
       "      <td>0.542415</td>\n",
       "      <td>0.762648</td>\n",
       "      <td>0.737778</td>\n",
       "      <td>0.791192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">random_forest</th>\n",
       "      <th>{'n_estimators': 25}</th>\n",
       "      <td>0.541519</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.736422</td>\n",
       "      <td>0.817991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'n_estimators': 10}</th>\n",
       "      <td>0.540631</td>\n",
       "      <td>0.769060</td>\n",
       "      <td>0.736179</td>\n",
       "      <td>0.806107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">logistic_regression</th>\n",
       "      <th>{'C': 10}</th>\n",
       "      <td>0.529895</td>\n",
       "      <td>0.824491</td>\n",
       "      <td>0.728237</td>\n",
       "      <td>0.952079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'C': 1}</th>\n",
       "      <td>0.529608</td>\n",
       "      <td>0.824747</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>0.952950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'C': 0.1}</th>\n",
       "      <td>0.527655</td>\n",
       "      <td>0.826136</td>\n",
       "      <td>0.727174</td>\n",
       "      <td>0.958110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">decision_tree</th>\n",
       "      <th>{'max_depth': 5}</th>\n",
       "      <td>0.526763</td>\n",
       "      <td>0.819946</td>\n",
       "      <td>0.727110</td>\n",
       "      <td>0.944480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'max_depth': 8}</th>\n",
       "      <td>0.526611</td>\n",
       "      <td>0.819675</td>\n",
       "      <td>0.726935</td>\n",
       "      <td>0.941844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">boosting</th>\n",
       "      <th>{'n_estimators': 50}</th>\n",
       "      <td>0.521058</td>\n",
       "      <td>0.828013</td>\n",
       "      <td>0.724194</td>\n",
       "      <td>0.968303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'n_estimators': 100}</th>\n",
       "      <td>0.520604</td>\n",
       "      <td>0.828232</td>\n",
       "      <td>0.723993</td>\n",
       "      <td>0.969238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'n_estimators': 30}</th>\n",
       "      <td>0.519701</td>\n",
       "      <td>0.828618</td>\n",
       "      <td>0.723591</td>\n",
       "      <td>0.970933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">logistic_regression</th>\n",
       "      <th>{'C': 0.01}</th>\n",
       "      <td>0.519186</td>\n",
       "      <td>0.828112</td>\n",
       "      <td>0.723411</td>\n",
       "      <td>0.969820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'C': 0.001}</th>\n",
       "      <td>0.503149</td>\n",
       "      <td>0.832748</td>\n",
       "      <td>0.716616</td>\n",
       "      <td>0.994514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           f1_score       auc  \\\n",
       "model               parameters                                  \n",
       "decision_tree       {'max_depth': 20}      0.545291  0.735545   \n",
       "bagging             {'n_estimators': 2}    0.543900  0.711505   \n",
       "random_forest       {'n_estimators': 1}    0.543246  0.732626   \n",
       "bagging             {'n_estimators': 20}   0.542575  0.767744   \n",
       "random_forest       {'n_estimators': 50}   0.542461  0.777961   \n",
       "bagging             {'n_estimators': 10}   0.542415  0.762648   \n",
       "random_forest       {'n_estimators': 25}   0.541519  0.774476   \n",
       "                    {'n_estimators': 10}   0.540631  0.769060   \n",
       "logistic_regression {'C': 10}              0.529895  0.824491   \n",
       "                    {'C': 1}               0.529608  0.824747   \n",
       "                    {'C': 0.1}             0.527655  0.826136   \n",
       "decision_tree       {'max_depth': 5}       0.526763  0.819946   \n",
       "                    {'max_depth': 8}       0.526611  0.819675   \n",
       "boosting            {'n_estimators': 50}   0.521058  0.828013   \n",
       "                    {'n_estimators': 100}  0.520604  0.828232   \n",
       "                    {'n_estimators': 30}   0.519701  0.828618   \n",
       "logistic_regression {'C': 0.01}            0.519186  0.828112   \n",
       "                    {'C': 0.001}           0.503149  0.832748   \n",
       "\n",
       "                                           precision_at_0.5  recall_at_0.5  \n",
       "model               parameters                                              \n",
       "decision_tree       {'max_depth': 20}              0.741371       0.732040  \n",
       "bagging             {'n_estimators': 2}            0.742334       0.685972  \n",
       "random_forest       {'n_estimators': 1}            0.740327       0.726616  \n",
       "bagging             {'n_estimators': 20}           0.737493       0.802282  \n",
       "random_forest       {'n_estimators': 50}           0.736741       0.825577  \n",
       "bagging             {'n_estimators': 10}           0.737778       0.791192  \n",
       "random_forest       {'n_estimators': 25}           0.736422       0.817991  \n",
       "                    {'n_estimators': 10}           0.736179       0.806107  \n",
       "logistic_regression {'C': 10}                      0.728237       0.952079  \n",
       "                    {'C': 1}                       0.728099       0.952950  \n",
       "                    {'C': 0.1}                     0.727174       0.958110  \n",
       "decision_tree       {'max_depth': 5}               0.727110       0.944480  \n",
       "                    {'max_depth': 8}               0.726935       0.941844  \n",
       "boosting            {'n_estimators': 50}           0.724194       0.968303  \n",
       "                    {'n_estimators': 100}          0.723993       0.969238  \n",
       "                    {'n_estimators': 30}           0.723591       0.970933  \n",
       "logistic_regression {'C': 0.01}                    0.723411       0.969820  \n",
       "                    {'C': 0.001}                   0.716616       0.994514  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model', 'parameters'])[['f1_score', 'auc', 'precision_at_0.5', 'recall_at_0.5']].mean().sort_values('f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run slow models\n",
    "df = run_the_models(data, ['boosting',\n",
    "                           'bagging', \n",
    "                           'random_forest', \n",
    "                           'decision_tree', \n",
    "                           'logistic_regression',\n",
    "                           'knn',\n",
    "                           'support_vector_machine'], response, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
